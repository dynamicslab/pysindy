{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Scikit-learn\n",
    "This notebook shows how PySINDy objects interface with some useful tools from [Scikit-learn](https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/dynamicslab/pysindy/v1.7.3?filepath=examples/4_scikit_learn_compatibility.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T22:47:55.509529Z",
     "start_time": "2020-08-22T22:47:54.323781Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "from pysindy.utils import lorenz\n",
    "import pysindy as ps\n",
    "\n",
    "# ignore user warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Integrator keywords for solve_ivp\n",
    "integrator_keywords = {}\n",
    "integrator_keywords['rtol'] = 1e-15\n",
    "integrator_keywords['method'] = 'LSODA'\n",
    "integrator_keywords['atol'] = 1e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some training data from the [Lorenz system](https://en.wikipedia.org/wiki/Lorenz_system) with which to experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T22:47:56.708081Z",
     "start_time": "2020-08-22T22:47:56.618948Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "dt = .002\n",
    "\n",
    "t_train = np.arange(0, 10, dt)\n",
    "t_train_span = (t_train[0], t_train[-1])\n",
    "x0_train = [-8, 8, 27]\n",
    "x_train = solve_ivp(lorenz, t_train_span, x0_train, \n",
    "                    t_eval=t_train, **integrator_keywords).y.T\n",
    "\n",
    "# Evolve the Lorenz equations in time using a different initial condition\n",
    "t_test = np.arange(0, 15, dt)\n",
    "t_test_span = (t_test[0], t_test[-1])\n",
    "x0_test = np.array([8, 7, 15])\n",
    "x_test = solve_ivp(lorenz, t_test_span, x0_test, \n",
    "                   t_eval=t_test, **integrator_keywords).y.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "PySINDy supports Scikit-learn-type cross-validation with a few caveats.\n",
    "\n",
    "1. We must use **uniform timesteps** using the `t_default` parameter. This is because the `fit` and `score` methods of `SINDy` differ from those used in Scikit-learn in the sense that they both have an optional `t` parameter. Setting `t_default` is a workaround.\n",
    "2. We have to be careful about the way we split up testing and training data during cross-validation. Because the `SINDy` object needs to differentiate the data, we need the training and test data to consist of sequential intervals of time. If we randomly sample the data, then the computed derivatives will be horribly inaccurate. Luckily, Scikit-learn has a `TimeSeriesSplit` object for such situations. If we really want to randomly sample the data during cross-validation, there is a way to do so. However, it's more complicated.\n",
    "\n",
    "Note that we need to prepend `optimizer__`, `feature_library__`, or `differentiation_method__` to the parameter names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation with TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T22:50:47.967603Z",
     "start_time": "2020-08-22T22:50:40.520544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'differentiation_method__order': 1, 'feature_library': PolynomialLibrary(), 'optimizer__alpha': 0.01, 'optimizer__threshold': 0.01}\n",
      "(x0)' = -10.021 x0 + 9.993 x1\n",
      "(x1)' = 0.227 1 + 27.601 x0 + -0.611 x1 + -0.983 x0 x2 + -0.020 x1 x2\n",
      "(x2)' = 0.590 1 + 0.045 x0 + -0.018 x1 + -2.691 x2 + 0.965 x0 x1 + 0.026 x1^2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "model = ps.SINDy(t_default=dt)\n",
    "\n",
    "param_grid = {\n",
    "    \"optimizer__threshold\": [0.001, 0.01, 0.1],\n",
    "    \"optimizer__alpha\": [0.01, 0.05, 0.1],\n",
    "    \"feature_library\": [ps.PolynomialLibrary(), ps.FourierLibrary()],\n",
    "    \"differentiation_method__order\": [1, 2]\n",
    "}\n",
    "\n",
    "search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=TimeSeriesSplit(n_splits=5)\n",
    ")\n",
    "search.fit(x_train)\n",
    "\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "search.best_estimator_.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some extra care must be taken when working with differentiation methods from the `derivative` package (i.e. those accessed via the `SINDyDerivative` class). See the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T22:59:18.558877Z",
     "start_time": "2020-08-22T22:58:57.908732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'differentiation_method__kwargs': {'kind': 'spline', 's': 0.01}, 'optimizer__threshold': 0.1}\n",
      "(x0)' = -10.000 x0 + 10.000 x1\n",
      "(x1)' = 28.003 x0 + -1.001 x1 + -1.000 x0 x2\n",
      "(x2)' = -2.667 x2 + 1.000 x0 x1\n"
     ]
    }
   ],
   "source": [
    "model = ps.SINDy(\n",
    "    t_default=dt,\n",
    "    differentiation_method=ps.SINDyDerivative(kind='spline', s=1e-2)\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"optimizer__threshold\": [0.001, 0.01, 0.1],\n",
    "    \"differentiation_method__kwargs\": [\n",
    "        {'kind': 'spline', 's': 1e-2},\n",
    "        {'kind': 'spline', 's': 1e-1},\n",
    "        {'kind': 'finite_difference', 'k': 1},\n",
    "        {'kind': 'finite_difference', 'k': 2},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# This part is identical to what we did before\n",
    "search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=TimeSeriesSplit(n_splits=5)\n",
    ")\n",
    "search.fit(x_train)\n",
    "\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "search.best_estimator_.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation without TimeSeriesSplit\n",
    "If we want to use another cross-validation splitter, we'll need to (a) define a wrapper class which uses the argument \"y\" instead of \"x_dot\" and (b) precompute the derivatives. Note that (b) means that we will not be able to perform cross-validation on the parameters of the differentiation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T22:59:50.283609Z",
     "start_time": "2020-08-22T22:59:50.261397Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "class SINDyCV(ps.SINDy):\n",
    "    def __init__(\n",
    "        self,\n",
    "        optimizer=None,\n",
    "        feature_library=None,\n",
    "        differentiation_method=None,\n",
    "        feature_names=None,\n",
    "        t_default=1,\n",
    "        discrete_time=False,\n",
    "    ):\n",
    "        super(SINDyCV, self).__init__(\n",
    "            optimizer=optimizer,\n",
    "            feature_library=feature_library,\n",
    "            differentiation_method=differentiation_method,\n",
    "            feature_names=feature_names,\n",
    "            t_default=t_default,\n",
    "            discrete_time=discrete_time,\n",
    "        )\n",
    "\n",
    "    def fit(self, x, y, **kwargs):\n",
    "        return super(SINDyCV, self).fit(x, x_dot=y, **kwargs)\n",
    "    \n",
    "    def score(\n",
    "        self,\n",
    "        x,\n",
    "        y,\n",
    "        t=None,\n",
    "        u=None,\n",
    "        multiple_trajectories=False,\n",
    "        metric=r2_score,\n",
    "        **metric_kws\n",
    "    ):\n",
    "        return super(SINDyCV, self).score(\n",
    "            x,\n",
    "            x_dot=y,\n",
    "            t=t,\n",
    "            u=u,\n",
    "            multiple_trajectories=multiple_trajectories,\n",
    "            metric=metric,\n",
    "            **metric_kws\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T22:59:56.316952Z",
     "start_time": "2020-08-22T22:59:52.131651Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'feature_library__degree': 2, 'optimizer__alpha': 0.01, 'optimizer__threshold': 0.002}\n",
      "(x0)' = -9.999 x0 + 9.999 x1\n",
      "(x1)' = 27.992 x0 + -0.999 x1 + -1.000 x0 x2\n",
      "(x2)' = -2.666 x2 + 1.000 x0 x1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "model = SINDyCV()\n",
    "x_dot = model.differentiate(x_train, t=t_train)\n",
    "\n",
    "param_grid = {\n",
    "    \"optimizer__threshold\": [0.002, 0.01, 0.1],\n",
    "    \"optimizer__alpha\": [0.01, 0.05, 0.1],\n",
    "    \"feature_library__degree\": [1, 2, 3],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(\n",
    "    model,\n",
    "    param_grid,\n",
    "    cv=ShuffleSplit(n_splits=3, test_size=0.25)\n",
    ")\n",
    "search.fit(x_train, y=x_dot)\n",
    "print(\"Best parameters:\", search.best_params_)\n",
    "search.best_estimator_.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse optimizers\n",
    "Any of Scikit-learn's [linear models ](https://scikit-learn.org/stable/modules/linear_model.html) can be used for the `optimizer` parameter of a `SINDy` object, though we only recommend using those designed for sparse regression.\n",
    "\n",
    "In the examples below we set `fit_intercept` to `False` since the default feature library (polynomials of degree up to two) already includes constant functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T22:59:59.313750Z",
     "start_time": "2020-08-22T22:59:58.992166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x0)' = -10.005 x0 + 10.003 x1\n",
      "(x1)' = 27.990 x0 + -0.997 x1 + -1.000 x0 x2\n",
      "(x2)' = -2.665 x2 + 0.001 x0^2 + 0.999 x0 x1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "model = ps.SINDy(optimizer=ElasticNet(l1_ratio=0.9, \n",
    "                                      fit_intercept=False), \n",
    "                 t_default=dt)\n",
    "model.fit(x_train)\n",
    "model.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T23:00:00.375038Z",
     "start_time": "2020-08-22T23:00:00.333557Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x0)' = -10.005 x0 + 10.003 x1\n",
      "(x1)' = 27.990 x0 + -0.997 x1 + -1.000 x0 x2\n",
      "(x2)' = -2.665 x2 + 0.001 x0^2 + 0.999 x0 x1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import OrthogonalMatchingPursuit\n",
    "\n",
    "model = ps.SINDy(\n",
    "    optimizer=OrthogonalMatchingPursuit(n_nonzero_coefs=8, \n",
    "                                        fit_intercept=False),\n",
    "    t_default=dt\n",
    ")\n",
    "model.fit(x_train)\n",
    "model.print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
